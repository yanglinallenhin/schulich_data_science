{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['gender'].fillna('Unknown', inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  customers['age'] = pd.cut(customers['age'].replace('Unknown', -1).astype(float), bins=bins, labels=labels)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['recency'].fillna((reference_date - customers['join_date']).dt.days, inplace=True)  # Fill NaN with join_date if no transaction\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['frequency'].fillna(0, inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:68: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['positive_response'].fillna(0, inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['transaction_diversity'].fillna(0, inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['transaction_standard_deviation'].fillna(0, inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:83: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['total_transactions'].fillna(0, inplace=True)\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:87: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['engagement_frequency'].replace([np.inf, -np.inf], 0, inplace=True)  # Handle division by zero\n",
      "/var/folders/03/qxtr7cc92pg1c6lvx8kqq6f80000gn/T/ipykernel_5028/2528757346.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  modeling_data['CLV_latest_year'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (7711, 1), indices imply (7711, 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(preprocessor\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_gender\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    138\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m num_features \u001b[38;5;241m+\u001b[39m cat_features\n\u001b[0;32m--> 139\u001b[0m X_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Print the transformed features\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m             arrays,\n\u001b[1;32m    861\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    877\u001b[0m         {},\n\u001b[1;32m    878\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    882\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (7711, 1), indices imply (7711, 24)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the datasets\n",
    "customers = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/customers_final.csv')\n",
    "engagements = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/engagements_final.csv')\n",
    "marketing = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/marketing_final.csv')\n",
    "transactions = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/transactions_final.csv')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "customers['join_date'] = pd.to_datetime(customers['join_date'])\n",
    "customers['last_purchase_date'] = pd.to_datetime(customers['last_purchase_date'])\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])\n",
    "marketing['campaign_date'] = pd.to_datetime(marketing['campaign_date'])\n",
    "\n",
    "# Fill missing values for gender with \"Unknown\"\n",
    "customers['gender'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill missing values in the age column with \"Unknown\"\n",
    "customers['age'] = customers['age'].fillna('Unknown')\n",
    "\n",
    "# Convert age into categorical ranges\n",
    "bins = [-1, 29, 39, 49, 59, np.inf]\n",
    "labels = ['0-29', '30-39', '40-49', '50-59', '60+']\n",
    "customers['age'] = pd.cut(customers['age'].replace('Unknown', -1).astype(float), bins=bins, labels=labels)\n",
    "customers['age'] = customers['age'].cat.add_categories('Unknown').fillna('Unknown')\n",
    "\n",
    "# Define the date range for the analysis\n",
    "start_date = '2023-06-01'\n",
    "end_date = '2024-05-31'\n",
    "reference_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Filter transactions within the specified period\n",
    "filtered_transactions = transactions[(transactions['transaction_date'] >= start_date) & (transactions['transaction_date'] <= end_date)]\n",
    "\n",
    "# Filter marketing data within the specified period\n",
    "filtered_marketing = marketing[(marketing['campaign_date'] >= start_date) & (marketing['campaign_date'] <= end_date)]\n",
    "\n",
    "# Feature Engineering\n",
    "# Recency: Days since last transaction\n",
    "last_transaction_date = filtered_transactions.groupby('customer_id')['transaction_date'].max().reset_index()\n",
    "last_transaction_date.columns = ['customer_id', 'last_transaction_date']\n",
    "customers = pd.merge(customers, last_transaction_date, on='customer_id', how='left')\n",
    "customers['recency'] = (reference_date - customers['last_purchase_date']).dt.days\n",
    "customers['recency'].fillna((reference_date - customers['join_date']).dt.days, inplace=True)  # Fill NaN with join_date if no transaction\n",
    "\n",
    "# Frequency: Number of transactions within the year\n",
    "transaction_frequency = filtered_transactions.groupby('customer_id').size().reset_index(name='frequency')\n",
    "customers = pd.merge(customers, transaction_frequency, on='customer_id', how='left')\n",
    "customers['frequency'].fillna(0, inplace=True)\n",
    "\n",
    "# Lifespan: Days from join date to reference date\n",
    "customers['lifespan'] = (reference_date - customers['join_date']).dt.days\n",
    "\n",
    "# Positive Response: Number of 'Yes' responses within the year\n",
    "positive_responses = filtered_marketing[filtered_marketing['response'] == 'Yes'].groupby('customer_id').size().reset_index(name='positive_response')\n",
    "customers = pd.merge(customers, positive_responses, on='customer_id', how='left')\n",
    "customers['positive_response'].fillna(0, inplace=True)\n",
    "\n",
    "# Transaction Diversity: Number of different product categories purchased within the year\n",
    "transaction_diversity = filtered_transactions.groupby('customer_id')['product_category'].nunique().reset_index(name='transaction_diversity')\n",
    "customers = pd.merge(customers, transaction_diversity, on='customer_id', how='left')\n",
    "customers['transaction_diversity'].fillna(0, inplace=True)\n",
    "\n",
    "# Transaction Standard Deviation: Standard deviation of transaction amounts within the year\n",
    "transaction_std = filtered_transactions.groupby('customer_id')['transaction_amount'].std().reset_index(name='transaction_standard_deviation')\n",
    "customers = pd.merge(customers, transaction_std, on='customer_id', how='left')\n",
    "customers['transaction_standard_deviation'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate total transactions per customer for proportion\n",
    "total_transactions = transactions.groupby('customer_id').size().reset_index(name='total_transactions')\n",
    "customers = pd.merge(customers, total_transactions, on='customer_id', how='left')\n",
    "customers['total_transactions'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate engagement frequency\n",
    "customers['engagement_frequency'] = np.where(customers['total_transactions'] == 0, 0, customers['frequency'] / customers['total_transactions'])\n",
    "customers['engagement_frequency'].replace([np.inf, -np.inf], 0, inplace=True)  # Handle division by zero\n",
    "\n",
    "# Merge engagement data and calculate engagement metrics\n",
    "customers = pd.merge(customers, engagements, on='customer_id', how='left')\n",
    "customers['site_visit'] = customers['number_of_site_visits'] * customers['engagement_frequency']\n",
    "customers['email_per_transaction'] = customers['number_of_emails_opened'] * customers['engagement_frequency']\n",
    "customers['click_per_transaction'] = customers['number_of_clicks'] * customers['engagement_frequency']\n",
    "\n",
    "# Fill NaN values in engagement features\n",
    "customers[['site_visit', 'email_per_transaction', 'click_per_transaction']] = customers[['site_visit', 'email_per_transaction', 'click_per_transaction']].fillna(0)\n",
    "\n",
    "# Create age-gender interaction term\n",
    "customers['age_gender'] = customers['age'].astype(str) + '_' + customers['gender'].astype(str)\n",
    "\n",
    "# Filter out customers who joined after 2023-06-01\n",
    "modeling_data = customers[customers['join_date'] < pd.to_datetime(start_date)]\n",
    "\n",
    "# Calculate CLV for the latest year (2023-06-01 to 2024-05-31)\n",
    "clv_latest_year = filtered_transactions.groupby('customer_id')['transaction_amount'].sum().reset_index()\n",
    "clv_latest_year.columns = ['customer_id', 'CLV_latest_year']\n",
    "\n",
    "# Merge the CLV data with modeling_data\n",
    "modeling_data = pd.merge(modeling_data, clv_latest_year, on='customer_id', how='left')\n",
    "modeling_data['CLV_latest_year'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the threshold for the top 25% of customers\n",
    "threshold = modeling_data['CLV_latest_year'].quantile(0.75)\n",
    "\n",
    "# Assign labels based on the threshold\n",
    "modeling_data['highvalue_customer'] = (modeling_data['CLV_latest_year'] >= threshold).astype(int)\n",
    "\n",
    "# Drop the frequency column\n",
    "modeling_data = modeling_data.drop(columns=['frequency'])\n",
    "\n",
    "# Independent variables\n",
    "independent_features = ['recency', 'lifespan', 'positive_response', 'site_visit', 'email_per_transaction', 'click_per_transaction', 'age_gender']\n",
    "\n",
    "# Define the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), independent_features[:-1]),  # All columns except 'age_gender'\n",
    "        ('cat', OneHotEncoder(), ['age_gender'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the transformations\n",
    "X = preprocessor.fit_transform(modeling_data[independent_features])\n",
    "\n",
    "# Convert the result back to a DataFrame for ease of use\n",
    "num_features = independent_features[:-1]\n",
    "cat_features = list(preprocessor.named_transformers_['cat'].get_feature_names_out(['age_gender']))\n",
    "feature_names = num_features + cat_features\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Print the transformed features\n",
    "print(X_df.head())\n",
    "\n",
    "# Prepare the target variable\n",
    "y = modeling_data['highvalue_customer']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "logreg_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_logreg),\n",
    "    'Precision': precision_score(y_test, y_pred_logreg),\n",
    "    'Recall': recall_score(y_test, y_pred_logreg),\n",
    "    'F1 Score': f1_score(y_test, y_pred_logreg)\n",
    "}\n",
    "\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "for metric, value in logreg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nLogistic Regression Coefficients:\")\n",
    "logreg_coefficients = pd.DataFrame(logreg.coef_.flatten(), index=feature_names, columns=['Coefficient'])\n",
    "print(logreg_coefficients)\n",
    "\n",
    "# Train and evaluate Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "nb_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_nb),\n",
    "    'Precision': precision_score(y_test, y_pred_nb),\n",
    "    'Recall': recall_score(y_test, y_pred_nb),\n",
    "    'F1 Score': f1_score(y_test, y_pred_nb)\n",
    "}\n",
    "\n",
    "print(\"\\nNaive Bayes Metrics:\")\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Train and evaluate KNN\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "knn_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_knn),\n",
    "    'Precision': precision_score(y_test, y_pred_knn),\n",
    "    'Recall': recall_score(y_test, y_pred_knn),\n",
    "    'F1 Score': f1_score(y_test, y_pred_knn)\n",
    "}\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Metrics:\")\n",
    "for metric, value in knn_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
